{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VietAnhLe2399/NLP_SentimentAnalysis/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbznV-1x00K"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiNp3ZB8zQtm",
        "outputId": "7bc9e669-ea3d-4555-8094-66f200c434d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qC5QNUVzSim",
        "outputId": "1fe3e05f-c12e-4050-b018-112857fd550e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " data_in_dataframe.csv\t'ML 5 labels'\t       preprocessing.ipynb\n",
            " data_mod.txt\t\t'ML Models'\t       read_data_NLP.ipynb\n",
            " dict\t\t\t'ML Models 5 labels'   student_manual.train.txt\n",
            " ML\t\t\t preprocessed_df.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTLg0sJM7ka3",
        "outputId": "2731ea95-0c17-4115-c79d-616bd4a6bc99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install pyvi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.5MB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 747kB 44.6MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F8NLY1Mzb0S"
      },
      "source": [
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "import re\n",
        "import string\n",
        "import codecs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI9NxcYMzsWt"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/data_in_dataframe.csv\" \"data_in_dataframe.csv\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB5BxSiu5b6L"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/dict/pos.txt\" \"pos.txt\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/dict/neg.txt\" \"neg.txt\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/dict/not.txt\" \"not.txt\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-jdeBJE59KZ"
      },
      "source": [
        "with codecs.open('neg.txt', 'r', encoding='UTF-8') as f:\n",
        "    neg = f.readlines()\n",
        "neg_list = [n.replace('\\n', '') for n in neg]\n",
        "\n",
        "with codecs.open('pos.txt', 'r', encoding='UTF-8') as f:\n",
        "    pos = f.readlines()\n",
        "pos_list = [n.replace('\\n', '') for n in pos]\n",
        "with codecs.open('not.txt', 'r', encoding='UTF-8') as f:\n",
        "    not_ = f.readlines()\n",
        "not_list = [n.replace('\\n', '') for n in not_]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-CoYB2S6N6e"
      },
      "source": [
        "VN_CHARS_LOWER = u'áº¡áº£Ã£Ã Ã¡Ã¢áº­áº§áº¥áº©áº«Äƒáº¯áº±áº·áº³áºµÃ³Ã²á»Ãµá»Ã´á»™á»•á»—á»“á»‘Æ¡á»á»›á»£á»Ÿá»¡Ã©Ã¨áº»áº¹áº½Ãªáº¿á»á»‡á»ƒá»…ÃºÃ¹á»¥á»§Å©Æ°á»±á»¯á»­á»«á»©Ã­Ã¬á»‹á»‰Ä©Ã½á»³á»·á»µá»¹Ä‘Ã°'\n",
        "VN_CHARS_UPPER = u'áº áº¢ÃƒÃ€ÃÃ‚áº¬áº¦áº¤áº¨áºªÄ‚áº®áº°áº¶áº²áº´Ã“Ã’á»ŒÃ•á»Ã”á»˜á»”á»–á»’á»Æ á»œá»šá»¢á»á» Ã‰Ãˆáººáº¸áº¼ÃŠáº¾á»€á»†á»‚á»„ÃšÃ™á»¤á»¦Å¨Æ¯á»°á»®á»¬á»ªá»¨ÃÃŒá»Šá»ˆÄ¨Ãá»²á»¶á»´á»¸ÃÄ'\n",
        "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-iLFjfZ6PHR"
      },
      "source": [
        "def normalize_text(text):\n",
        "\n",
        "    #Remove cÃ¡c kÃ½ tá»± kÃ©o dÃ i: vd: Ä‘áº¹ppppppp\n",
        "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng\n",
        "    text = text.lower()\n",
        "\n",
        "    #Chuáº©n hÃ³a tiáº¿ng Viá»‡t, xá»­ lÃ½ emoj, chuáº©n hÃ³a tiáº¿ng Anh, thuáº­t ngá»¯\n",
        "    replace_list = {\n",
        "        'Ã²a': 'oÃ ', 'Ã³a': 'oÃ¡', 'á»a': 'oáº£', 'Ãµa': 'oÃ£', 'á»a': 'oáº¡', 'Ã²e': 'oÃ¨', 'Ã³e': 'oÃ©','á»e': 'oáº»',\n",
        "        'Ãµe': 'oáº½', 'á»e': 'oáº¹', 'Ã¹y': 'uá»³', 'Ãºy': 'uÃ½', 'á»§y': 'uá»·', 'Å©y': 'uá»¹','á»¥y': 'uá»µ', 'uáº£': 'á»§a',\n",
        "        'aÌ‰': 'áº£', 'Ã´Ì': 'á»‘', 'uÂ´': 'á»‘','Ã´Ìƒ': 'á»—', 'Ã´Ì€': 'á»“', 'Ã´Ì‰': 'á»•', 'Ã¢Ì': 'áº¥', 'Ã¢Ìƒ': 'áº«', 'Ã¢Ì‰': 'áº©',\n",
        "        'Ã¢Ì€': 'áº§', 'oÌ‰': 'á»', 'ÃªÌ€': 'á»','ÃªÌƒ': 'á»…', 'ÄƒÌ': 'áº¯', 'uÌ‰': 'á»§', 'ÃªÌ': 'áº¿', 'Æ¡Ì‰': 'á»Ÿ', 'iÌ‰': 'á»‰',\n",
        "        'eÌ‰': 'áº»', 'Ã k': u' Ã  ','aË‹': 'Ã ', 'iË‹': 'Ã¬', 'ÄƒÂ´': 'áº¯','Æ°Ì‰': 'á»­', 'eËœ': 'áº½', 'yËœ': 'á»¹', 'aÂ´': 'Ã¡',\n",
        "        #Quy cÃ¡c icon vá» 2 loáº¡i emoj: TÃ­ch cá»±c hoáº·c tiÃªu cá»±c\n",
        "        \"ğŸ‘¹\": \"negative\", \"ğŸ‘»\": \"positive\", \"ğŸ’ƒ\": \"positive\",'ğŸ¤™': ' positive ', 'ğŸ‘': ' positive ',\n",
        "        \"ğŸ’„\": \"positive\", \"ğŸ’\": \"positive\", \"ğŸ’©\": \"positive\",\"ğŸ˜•\": \"negative\", \"ğŸ˜±\": \"negative\", \"ğŸ˜¸\": \"positive\",\n",
        "        \"ğŸ˜¾\": \"negative\", \"ğŸš«\": \"negative\",  \"ğŸ¤¬\": \"negative\",\"ğŸ§š\": \"positive\", \"ğŸ§¡\": \"positive\",'ğŸ¶':' positive ',\n",
        "        'ğŸ‘': ' negative ', 'ğŸ˜£': ' negative ','âœ¨': ' negative ', 'â£': ' positive ','â˜€': ' positive ',\n",
        "        'â™¥': ' positive ', 'ğŸ¤©': ' positive ', 'like': ' positive ', 'ğŸ’Œ': ' positive ',\n",
        "        'ğŸ¤£': ' positive ', 'ğŸ–¤': ' positive ', 'ğŸ¤¤': ' positive ', ':(': ' negative ', 'ğŸ˜¢': ' negative ',\n",
        "        'â¤': ' positive ', 'ğŸ˜': ' positive ', 'ğŸ˜˜': ' positive ', 'ğŸ˜ª': ' negative ', 'ğŸ˜Š': ' positive ',\n",
        "        '?': ' ? ', 'ğŸ˜': ' positive ', 'ğŸ’–': ' positive ', 'ğŸ˜Ÿ': ' negative ', 'ğŸ˜­': ' negative ',\n",
        "        'ğŸ’¯': ' positive ', 'ğŸ’—': ' positive ', 'â™¡': ' positive ', 'ğŸ’œ': ' positive ', 'ğŸ¤—': ' positive ',\n",
        "        '^^': ' positive ', 'ğŸ˜¨': ' negative ', 'â˜º': ' positive ', 'ğŸ’‹': ' positive ', 'ğŸ‘Œ': ' positive ',\n",
        "        'ğŸ˜–': ' negative ', 'ğŸ˜€': ' positive ', ':((': ' negative ', 'ğŸ˜¡': ' negative ', 'ğŸ˜ ': ' negative ',\n",
        "        'ğŸ˜’': ' negative ', 'ğŸ™‚': ' positive ', 'ğŸ˜': ' negative ', 'ğŸ˜': ' positive ', 'ğŸ˜„': ' positive ',\n",
        "        'ğŸ˜™': ' positive ', 'ğŸ˜¤': ' negative ', 'ğŸ˜': ' positive ', 'ğŸ˜†': ' positive ', 'ğŸ’š': ' positive ',\n",
        "        'âœŒ': ' positive ', 'ğŸ’•': ' positive ', 'ğŸ˜': ' negative ', 'ğŸ˜“': ' negative ', 'ï¸ğŸ†—ï¸': ' positive ',\n",
        "        'ğŸ˜‰': ' positive ', 'ğŸ˜‚': ' positive ', ':v': '  positive ', '=))': '  positive ', 'ğŸ˜‹': ' positive ',\n",
        "        'ğŸ’“': ' positive ', 'ğŸ˜': ' negative ', ':3': ' positive ', 'ğŸ˜«': ' negative ', 'ğŸ˜¥': ' negative ',\n",
        "        'ğŸ˜ƒ': ' positive ', 'ğŸ˜¬': ' ğŸ˜¬ ', 'ğŸ˜Œ': ' ğŸ˜Œ ', 'ğŸ’›': ' positive ', 'ğŸ¤': ' positive ', 'ğŸˆ': ' positive ',\n",
        "        'ğŸ˜—': ' positive ', 'ğŸ¤”': ' negative ', 'ğŸ˜‘': ' negative ', 'ğŸ”¥': ' negative ', 'ğŸ™': ' negative ',\n",
        "        'ğŸ†—': ' positive ', 'ğŸ˜»': ' positive ', 'ğŸ’™': ' positive ', 'ğŸ’Ÿ': ' positive ',\n",
        "        'ğŸ˜š': ' positive ', 'âŒ': ' negative ', 'ğŸ‘': ' positive ', ';)': ' positive ', '<3': ' positive ',\n",
        "        'ğŸŒ': ' positive ',  'ğŸŒ·': ' positive ', 'ğŸŒ¸': ' positive ', 'ğŸŒº': ' positive ',\n",
        "        'ğŸŒ¼': ' positive ', 'ğŸ“': ' positive ', 'ğŸ…': ' positive ', 'ğŸ¾': ' positive ', 'ğŸ‘‰': ' positive ',\n",
        "        'ğŸ’': ' positive ', 'ğŸ’': ' positive ', 'ğŸ’¥': ' positive ', 'ğŸ’ª': ' positive ',\n",
        "        'ğŸ’°': ' positive ',  'ğŸ˜‡': ' positive ', 'ğŸ˜›': ' positive ', 'ğŸ˜œ': ' positive ',\n",
        "        'ğŸ™ƒ': ' positive ', 'ğŸ¤‘': ' positive ', 'ğŸ¤ª': ' positive ','â˜¹': ' negative ',  'ğŸ’€': ' negative ',\n",
        "        'ğŸ˜”': ' negative ', 'ğŸ˜§': ' negative ', 'ğŸ˜©': ' negative ', 'ğŸ˜°': ' negative ', 'ğŸ˜³': ' negative ',\n",
        "        'ğŸ˜µ': ' negative ', 'ğŸ˜¶': ' negative ', 'ğŸ™': ' negative ',\n",
        "        #Chuáº©n hÃ³a 1 sá»‘ sentiment words/English words\n",
        "        ':))': '  positive ', ':)': ' positive ', 'Ã´ kÃªi': ' ok ', 'okie': ' ok ', ' o kÃª ': ' ok ',\n",
        "        'okey': ' ok ', 'Ã´kÃª': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okÃª':' ok ',\n",
        "        ' tks ': u' cÃ¡m Æ¡n ', 'thks': u' cÃ¡m Æ¡n ', 'thanks': u' cÃ¡m Æ¡n ', 'ths': u' cÃ¡m Æ¡n ', 'thank': u' cÃ¡m Æ¡n ',\n",
        "        'â­': 'star ', '*': 'star ', 'ğŸŒŸ': 'star ', 'ğŸ‰': u' positive ',\n",
        "        'kg ': u' khÃ´ng ','not': u' khÃ´ng ', u' kg ': u' khÃ´ng ', '\"k ': u' khÃ´ng ',' kh ':u' khÃ´ng ','kÃ´':u' khÃ´ng ','hok':u' khÃ´ng ',' kp ': u' khÃ´ng pháº£i ',u' kÃ´ ': u' khÃ´ng ', '\"ko ': u' khÃ´ng ', u' ko ': u' khÃ´ng ', u' k ': u' khÃ´ng ', 'khong': u' khÃ´ng ', u' hok ': u' khÃ´ng ',\n",
        "        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
        "        ' lol ': ' negative ',' cc ': ' negative ','cute': u' dá»… thÆ°Æ¡ng ','huhu': ' negative ', ' vs ': u' vá»›i ', 'wa': ' quÃ¡ ', 'wÃ¡': u' quÃ¡', 'j': u' gÃ¬ ', 'â€œ': ' ',\n",
        "        ' sz ': u' cá»¡ ', 'size': u' cá»¡ ', u' Ä‘x ': u' Ä‘Æ°á»£c ', 'dk': u' Ä‘Æ°á»£c ', 'dc': u' Ä‘Æ°á»£c ', 'Ä‘k': u' Ä‘Æ°á»£c ',\n",
        "        'Ä‘c': u' Ä‘Æ°á»£c ','authentic': u' chuáº©n chÃ­nh hÃ£ng ',u' aut ': u' chuáº©n chÃ­nh hÃ£ng ', u' auth ': u' chuáº©n chÃ­nh hÃ£ng ', 'thick': u' positive ', 'store': u' cá»­a hÃ ng ',\n",
        "        'shop': u' cá»­a hÃ ng ', 'sp': u' sáº£n pháº©m ', 'gud': u' tá»‘t ','god': u' tá»‘t ','wel done':' tá»‘t ', 'good': u' tá»‘t ', 'gÃºt': u' tá»‘t ',\n",
        "        'sáº¥u': u' xáº¥u ','gut': u' tá»‘t ', u' tot ': u' tá»‘t ', u' nice ': u' tá»‘t ', 'perfect': 'ráº¥t tá»‘t', 'bt': u' bÃ¬nh thÆ°á»ng ',\n",
        "        'time': u' thá»i gian ', 'qÃ¡': u' quÃ¡ ', u' ship ': u' giao hÃ ng ', u' m ': u' mÃ¬nh ', u' mik ': u' mÃ¬nh ',\n",
        "        'ÃªÌ‰': 'á»ƒ', 'product': 'sáº£n pháº©m', 'quality': 'cháº¥t lÆ°á»£ng','chat':' cháº¥t ', 'excelent': 'hoÃ n háº£o', 'bad': 'tá»‡','fresh': ' tÆ°Æ¡i ','sad': ' tá»‡ ',\n",
        "        'date': u' háº¡n sá»­ dá»¥ng ', 'hsd': u' háº¡n sá»­ dá»¥ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hÃ ng ',u' sÃ­p ': u' giao hÃ ng ',\n",
        "        'beautiful': u' Ä‘áº¹p tuyá»‡t vá»i ', u' tl ': u' tráº£ lá»i ', u' r ': u' rá»“i ', u' shopE ': u' cá»­a hÃ ng ',u' order ': u' Ä‘áº·t hÃ ng ',\n",
        "        'cháº¥t lg': u' cháº¥t lÆ°á»£ng ',u' sd ': u' sá»­ dá»¥ng ',u' dt ': u' Ä‘iá»‡n thoáº¡i ',u' nt ': u' nháº¯n tin ',u' tl ': u' tráº£ lá»i ',u' sÃ i ': u' xÃ i ',u'bjo':u' bao giá» ',\n",
        "        'thik': u' thÃ­ch ',u' sop ': u' cá»­a hÃ ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' ráº¥t ',u'quáº£ ng ':u' quáº£ng  ',\n",
        "        'dep': u' Ä‘áº¹p ',u' xau ': u' xáº¥u ','delicious': u' ngon ', u'hÃ g': u' hÃ ng ', u'qá»§a': u' quáº£ ',\n",
        "        'iu': u' yÃªu ','fake': u' giáº£ máº¡o ', 'trl': 'tráº£ lá»i', '><': u' positive ',\n",
        "        ' por ': u' tá»‡ ',' poor ': u' tá»‡ ', 'ib':u' nháº¯n tin ', 'rep':u' tráº£ lá»i ',u'fback':' feedback ','fedback':' feedback ',\n",
        "        #dÆ°á»›i 3* quy vá» 1*, trÃªn 3* quy vá» 5*\n",
        "        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n",
        "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n",
        "        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}\n",
        "\n",
        "    for k, v in replace_list.items():\n",
        "        text = text.replace(k, v)\n",
        "\n",
        "    # chuyen punctuation thÃ nh space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = ViTokenizer.tokenize(text)\n",
        "    texts = text.split()\n",
        "    len_text = len(texts)\n",
        "\n",
        "    texts = [t.replace('_', ' ') for t in texts]\n",
        "    for i in range(len_text):\n",
        "        cp_text = texts[i]\n",
        "        if cp_text in not_list: # Xá»­ lÃ½ váº¥n Ä‘á» phá»§ Ä‘á»‹nh (VD: Ã¡o nÃ y cháº³ng Ä‘áº¹p--> Ã¡o nÃ y notpos)\n",
        "            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n",
        "\n",
        "            for j in range(numb_word):\n",
        "                if texts[i + j + 1] in pos_list:\n",
        "                    texts[i] = 'notpos'\n",
        "                    texts[i + j + 1] = ''\n",
        "\n",
        "                if texts[i + j + 1] in neg_list:\n",
        "                    texts[i] = 'notneg'\n",
        "                    texts[i + j + 1] = ''\n",
        "        else: #ThÃªm feature cho nhá»¯ng sentiment words (Ã¡o nÃ y Ä‘áº¹p--> Ã¡o nÃ y Ä‘áº¹p positive)\n",
        "            if cp_text in pos_list:\n",
        "                texts.append('positive')\n",
        "            elif cp_text in neg_list:\n",
        "                texts.append('negative')\n",
        "\n",
        "    text = u' '.join(texts)\n",
        "\n",
        "    #remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a thÃ£i\n",
        "    text = text.replace(u'\"', u' ')\n",
        "    text = text.replace(u'ï¸', u'')\n",
        "    text = text.replace('ğŸ»','')\n",
        "    return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beGHCeZaxnbt"
      },
      "source": [
        "df = pd.read_csv(\"data_in_dataframe.csv\", sep='\\t')\n",
        "del df['Unnamed: 0']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK_cY1tL7AZf",
        "outputId": "035a44a3-34a6-4604-e373-5cdd67219b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(len(df)):\n",
        "  te = normalize_text(df.loc[i, 'sentence'])\n",
        "  df.loc[i, 'sentence'] = te\n",
        "  print('\\r', i*100/len(df), '%', end='')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 99.99682136045773 %"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qGoVjDi7RbM",
        "outputId": "55aa3f3e-6f9f-4879-814d-b5d07f9a1e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>type</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ã¡o bao Ä‘áº¹p áº¡ positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tuyá»‡t vá»i positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2day ao khÃ´ng giong trong</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mÃ¹i thÆ¡m bÃ´i lÃªn da má»m da negative positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>váº£i Ä‘áº¹p dÃ y dáº·n positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31455</th>\n",
              "      <td>khÃ´ng Ä‘Ã¡ng tiá»n</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31456</th>\n",
              "      <td>quáº§n ráº¥t Ä‘áº¹p positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31457</th>\n",
              "      <td>hÃ ng Ä‘áº¹p Ä‘Ãºng giÃ¡ tiá»n positive positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31458</th>\n",
              "      <td>cháº¥t váº£i khÃ¡ á»•n positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31459</th>\n",
              "      <td>Ã¡o ráº¥t ok nhÃ© váº£i má»‹n len cao cá»• nÃ y phá»‘i form...</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31460 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence type  point\n",
              "0                                  Ã¡o bao Ä‘áº¹p áº¡ positive  POS      5\n",
              "1                                     tuyá»‡t vá»i positive  POS      5\n",
              "2                              2day ao khÃ´ng giong trong  NEG      1\n",
              "3           mÃ¹i thÆ¡m bÃ´i lÃªn da má»m da negative positive  POS      5\n",
              "4                               váº£i Ä‘áº¹p dÃ y dáº·n positive  POS      5\n",
              "...                                                  ...  ...    ...\n",
              "31455                                    khÃ´ng Ä‘Ã¡ng tiá»n  NEG      1\n",
              "31456                              quáº§n ráº¥t Ä‘áº¹p positive  POS      5\n",
              "31457           hÃ ng Ä‘áº¹p Ä‘Ãºng giÃ¡ tiá»n positive positive  POS      5\n",
              "31458                           cháº¥t váº£i khÃ¡ á»•n positive  POS      4\n",
              "31459  Ã¡o ráº¥t ok nhÃ© váº£i má»‹n len cao cá»• nÃ y phá»‘i form...  POS      5\n",
              "\n",
              "[31460 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7htJocBG7QX6"
      },
      "source": [
        "df.to_csv('preprocessed_df.csv', sep='\\t', index=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwnvF_GSz1S4"
      },
      "source": [
        "!cp preprocessed_df.csv drive/My\\ 'Drive/Colab Notebooks/NLP_1920_FinalExam'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5UZjlxj4txT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}