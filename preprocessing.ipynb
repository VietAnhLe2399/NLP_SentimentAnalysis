{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VietAnhLee/NLP_1920_FinalExam/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbznV-1x00K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiNp3ZB8zQtm",
        "colab_type": "code",
        "outputId": "6434acb5-3652-4427-fad6-b680798048ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qC5QNUVzSim",
        "colab_type": "code",
        "outputId": "2e280f90-47a9-4928-8b3b-4907e7e59287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aivivn\t\t       data_mod.txt\t    read_data_NLP.ipynb\n",
            "data_in_dataframe.csv  preprocessing.ipynb  student_manual.train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTLg0sJM7ka3",
        "colab_type": "code",
        "outputId": "17be0523-4bd2-44f0-b8e7-24b13a3c8b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "!pip install pyvi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/73/89be26d66c71f3bcca1de13bb73a9d622fabe282b55e518d68e86081d4e6/pyvi-0.0.9.7-py2.py3-none-any.whl (8.7MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.8MB 2.9MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.28.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 757kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.14.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.6 pyvi-0.0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F8NLY1Mzb0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "import re\n",
        "import string\n",
        "import codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI9NxcYMzsWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/data_in_dataframe.csv\" \"data_in_dataframe.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB5BxSiu5b6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/aivivn/pos.txt\" \"pos.txt\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/aivivn/nag.txt\" \"nag.txt\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/NLP_1920_FinalExam/aivivn/not.txt\" \"not.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-jdeBJE59KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('nag.txt', 'r', encoding='UTF-8') as f:\n",
        "    nag = f.readlines()\n",
        "nag_list = [n.replace('\\n', '') for n in nag]\n",
        "\n",
        "with codecs.open('pos.txt', 'r', encoding='UTF-8') as f:\n",
        "    pos = f.readlines()\n",
        "pos_list = [n.replace('\\n', '') for n in pos]\n",
        "with codecs.open('not.txt', 'r', encoding='UTF-8') as f:\n",
        "    not_ = f.readlines()\n",
        "not_list = [n.replace('\\n', '') for n in not_]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-CoYB2S6N6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VN_CHARS_LOWER = u'·∫°·∫£√£√†√°√¢·∫≠·∫ß·∫•·∫©·∫´ƒÉ·∫Ø·∫±·∫∑·∫≥·∫µ√≥√≤·ªç√µ·ªè√¥·ªô·ªï·ªó·ªì·ªë∆°·ªù·ªõ·ª£·ªü·ª°√©√®·∫ª·∫π·∫Ω√™·∫ø·ªÅ·ªá·ªÉ·ªÖ√∫√π·ª•·ªß≈©∆∞·ª±·ªØ·ª≠·ª´·ª©√≠√¨·ªã·ªâƒ©√Ω·ª≥·ª∑·ªµ·ªπƒë√∞'\n",
        "VN_CHARS_UPPER = u'·∫†·∫¢√É√Ä√Å√Ç·∫¨·∫¶·∫§·∫®·∫™ƒÇ·∫Æ·∫∞·∫∂·∫≤·∫¥√ì√í·ªå√ï·ªé√î·ªò·ªî·ªñ·ªí·ªê∆†·ªú·ªö·ª¢·ªû·ª†√â√à·∫∫·∫∏·∫º√ä·∫æ·ªÄ·ªÜ·ªÇ·ªÑ√ö√ô·ª§·ª¶≈®∆Ø·ª∞·ªÆ·ª¨·ª™·ª®√ç√å·ªä·ªàƒ®√ù·ª≤·ª∂·ª¥·ª∏√êƒê'\n",
        "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-iLFjfZ6PHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_text(text):\n",
        "\n",
        "    #Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp\n",
        "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n",
        "    text = text.lower()\n",
        "\n",
        "    #Chu·∫©n h√≥a ti·∫øng Vi·ªát, x·ª≠ l√Ω emoj, chu·∫©n h√≥a ti·∫øng Anh, thu·∫≠t ng·ªØ\n",
        "    replace_list = {\n",
        "        '√≤a': 'o√†', '√≥a': 'o√°', '·ªèa': 'o·∫£', '√µa': 'o√£', '·ªça': 'o·∫°', '√≤e': 'o√®', '√≥e': 'o√©','·ªèe': 'o·∫ª',\n",
        "        '√µe': 'o·∫Ω', '·ªçe': 'o·∫π', '√πy': 'u·ª≥', '√∫y': 'u√Ω', '·ªßy': 'u·ª∑', '≈©y': 'u·ªπ','·ª•y': 'u·ªµ', 'u·∫£': '·ªßa',\n",
        "        'aÃâ': '·∫£', '√¥ÃÅ': '·ªë', 'u¬¥': '·ªë','√¥ÃÉ': '·ªó', '√¥ÃÄ': '·ªì', '√¥Ãâ': '·ªï', '√¢ÃÅ': '·∫•', '√¢ÃÉ': '·∫´', '√¢Ãâ': '·∫©',\n",
        "        '√¢ÃÄ': '·∫ß', 'oÃâ': '·ªè', '√™ÃÄ': '·ªÅ','√™ÃÉ': '·ªÖ', 'ƒÉÃÅ': '·∫Ø', 'uÃâ': '·ªß', '√™ÃÅ': '·∫ø', '∆°Ãâ': '·ªü', 'iÃâ': '·ªâ',\n",
        "        'eÃâ': '·∫ª', '√†k': u' √† ','aÀã': '√†', 'iÀã': '√¨', 'ƒÉ¬¥': '·∫Ø','∆∞Ãâ': '·ª≠', 'eÀú': '·∫Ω', 'yÀú': '·ªπ', 'a¬¥': '√°',\n",
        "        #Quy c√°c icon v·ªÅ 2 lo·∫°i emoj: T√≠ch c·ª±c ho·∫∑c ti√™u c·ª±c\n",
        "        \"üëπ\": \"nagative\", \"üëª\": \"positive\", \"üíÉ\": \"positive\",'ü§ô': ' positive ', 'üëç': ' positive ',\n",
        "        \"üíÑ\": \"positive\", \"üíé\": \"positive\", \"üí©\": \"positive\",\"üòï\": \"nagative\", \"üò±\": \"nagative\", \"üò∏\": \"positive\",\n",
        "        \"üòæ\": \"nagative\", \"üö´\": \"nagative\",  \"ü§¨\": \"nagative\",\"üßö\": \"positive\", \"üß°\": \"positive\",'üê∂':' positive ',\n",
        "        'üëé': ' nagative ', 'üò£': ' nagative ','‚ú®': ' positive ', '‚ù£': ' positive ','‚òÄ': ' positive ',\n",
        "        '‚ô•': ' positive ', 'ü§©': ' positive ', 'like': ' positive ', 'üíå': ' positive ',\n",
        "        'ü§£': ' positive ', 'üñ§': ' positive ', 'ü§§': ' positive ', ':(': ' nagative ', 'üò¢': ' nagative ',\n",
        "        '‚ù§': ' positive ', 'üòç': ' positive ', 'üòò': ' positive ', 'üò™': ' nagative ', 'üòä': ' positive ',\n",
        "        '?': ' ? ', 'üòÅ': ' positive ', 'üíñ': ' positive ', 'üòü': ' nagative ', 'üò≠': ' nagative ',\n",
        "        'üíØ': ' positive ', 'üíó': ' positive ', '‚ô°': ' positive ', 'üíú': ' positive ', 'ü§ó': ' positive ',\n",
        "        '^^': ' positive ', 'üò®': ' nagative ', '‚ò∫': ' positive ', 'üíã': ' positive ', 'üëå': ' positive ',\n",
        "        'üòñ': ' nagative ', 'üòÄ': ' positive ', ':((': ' nagative ', 'üò°': ' nagative ', 'üò†': ' nagative ',\n",
        "        'üòí': ' nagative ', 'üôÇ': ' positive ', 'üòè': ' nagative ', 'üòù': ' positive ', 'üòÑ': ' positive ',\n",
        "        'üòô': ' positive ', 'üò§': ' nagative ', 'üòé': ' positive ', 'üòÜ': ' positive ', 'üíö': ' positive ',\n",
        "        '‚úå': ' positive ', 'üíï': ' positive ', 'üòû': ' nagative ', 'üòì': ' nagative ', 'Ô∏èüÜóÔ∏è': ' positive ',\n",
        "        'üòâ': ' positive ', 'üòÇ': ' positive ', ':v': '  positive ', '=))': '  positive ', 'üòã': ' positive ',\n",
        "        'üíì': ' positive ', 'üòê': ' nagative ', ':3': ' positive ', 'üò´': ' nagative ', 'üò•': ' nagative ',\n",
        "        'üòÉ': ' positive ', 'üò¨': ' üò¨ ', 'üòå': ' üòå ', 'üíõ': ' positive ', 'ü§ù': ' positive ', 'üéà': ' positive ',\n",
        "        'üòó': ' positive ', 'ü§î': ' nagative ', 'üòë': ' nagative ', 'üî•': ' nagative ', 'üôè': ' nagative ',\n",
        "        'üÜó': ' positive ', 'üòª': ' positive ', 'üíô': ' positive ', 'üíü': ' positive ',\n",
        "        'üòö': ' positive ', '‚ùå': ' nagative ', 'üëè': ' positive ', ';)': ' positive ', '<3': ' positive ',\n",
        "        'üåù': ' positive ',  'üå∑': ' positive ', 'üå∏': ' positive ', 'üå∫': ' positive ',\n",
        "        'üåº': ' positive ', 'üçì': ' positive ', 'üêÖ': ' positive ', 'üêæ': ' positive ', 'üëâ': ' positive ',\n",
        "        'üíê': ' positive ', 'üíû': ' positive ', 'üí•': ' positive ', 'üí™': ' positive ',\n",
        "        'üí∞': ' positive ',  'üòá': ' positive ', 'üòõ': ' positive ', 'üòú': ' positive ',\n",
        "        'üôÉ': ' positive ', 'ü§ë': ' positive ', 'ü§™': ' positive ','‚òπ': ' nagative ',  'üíÄ': ' nagative ',\n",
        "        'üòî': ' nagative ', 'üòß': ' nagative ', 'üò©': ' nagative ', 'üò∞': ' nagative ', 'üò≥': ' nagative ',\n",
        "        'üòµ': ' nagative ', 'üò∂': ' nagative ', 'üôÅ': ' nagative ',\n",
        "        #Chu·∫©n h√≥a 1 s·ªë sentiment words/English words\n",
        "        ':))': '  positive ', ':)': ' positive ', '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ',\n",
        "        'okey': ' ok ', '√¥k√™': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','ok√™':' ok ',\n",
        "        ' tks ': u' c√°m ∆°n ', 'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',\n",
        "        '‚≠ê': 'star ', '*': 'star ', 'üåü': 'star ', 'üéâ': u' positive ',\n",
        "        'kg ': u' kh√¥ng ','not': u' kh√¥ng ', u' kg ': u' kh√¥ng ', '\"k ': u' kh√¥ng ',' kh ':u' kh√¥ng ','k√¥':u' kh√¥ng ','hok':u' kh√¥ng ',' kp ': u' kh√¥ng ph·∫£i ',u' k√¥ ': u' kh√¥ng ', '\"ko ': u' kh√¥ng ', u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ', 'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ',\n",
        "        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
        "        ' lol ': ' nagative ',' cc ': ' nagative ','cute': u' d·ªÖ th∆∞∆°ng ','huhu': ' nagative ', ' vs ': u' v·ªõi ', 'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',\n",
        "        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',\n",
        "        'ƒëc': u' ƒë∆∞·ª£c ','authentic': u' chu·∫©n ch√≠nh h√£ng ',u' aut ': u' chu·∫©n ch√≠nh h√£ng ', u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u' positive ', 'store': u' c·ª≠a h√†ng ',\n",
        "        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ','god': u' t·ªët ','wel done':' t·ªët ', 'good': u' t·ªët ', 'g√∫t': u' t·ªët ',\n",
        "        's·∫•u': u' x·∫•u ','gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët', 'bt': u' b√¨nh th∆∞·ªùng ',\n",
        "        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',\n",
        "        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng','chat':' ch·∫•t ', 'excelent': 'ho√†n h·∫£o', 'bad': 't·ªá','fresh': ' t∆∞∆°i ','sad': ' t·ªá ',\n",
        "        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao h√†ng ',u' s√≠p ': u' giao h√†ng ',\n",
        "        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' tl ': u' tr·∫£ l·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ',u' order ': u' ƒë·∫∑t h√†ng ',\n",
        "        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ',u' sd ': u' s·ª≠ d·ª•ng ',u' dt ': u' ƒëi·ªán tho·∫°i ',u' nt ': u' nh·∫Øn tin ',u' tl ': u' tr·∫£ l·ªùi ',u' s√†i ': u' x√†i ',u'bjo':u' bao gi·ªù ',\n",
        "        'thik': u' th√≠ch ',u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',u'qu·∫£ ng ':u' qu·∫£ng  ',\n",
        "        'dep': u' ƒë·∫πp ',u' xau ': u' x·∫•u ','delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',\n",
        "        'iu': u' y√™u ','fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u' positive ',\n",
        "        ' por ': u' t·ªá ',' poor ': u' t·ªá ', 'ib':u' nh·∫Øn tin ', 'rep':u' tr·∫£ l·ªùi ',u'fback':' feedback ','fedback':' feedback ',\n",
        "        #d∆∞·ªõi 3* quy v·ªÅ 1*, tr√™n 3* quy v·ªÅ 5*\n",
        "        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n",
        "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n",
        "        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}\n",
        "\n",
        "    for k, v in replace_list.items():\n",
        "        text = text.replace(k, v)\n",
        "\n",
        "    # chuyen punctuation th√†nh space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = ViTokenizer.tokenize(text)\n",
        "    texts = text.split()\n",
        "    len_text = len(texts)\n",
        "\n",
        "    texts = [t.replace('_', ' ') for t in texts]\n",
        "    for i in range(len_text):\n",
        "        cp_text = texts[i]\n",
        "        if cp_text in not_list: # X·ª≠ l√Ω v·∫•n ƒë·ªÅ ph·ªß ƒë·ªãnh (VD: √°o n√†y ch·∫≥ng ƒë·∫πp--> √°o n√†y notpos)\n",
        "            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n",
        "\n",
        "            for j in range(numb_word):\n",
        "                if texts[i + j + 1] in pos_list:\n",
        "                    texts[i] = 'notpos'\n",
        "                    texts[i + j + 1] = ''\n",
        "\n",
        "                if texts[i + j + 1] in nag_list:\n",
        "                    texts[i] = 'notnag'\n",
        "                    texts[i + j + 1] = ''\n",
        "        else: #Th√™m feature cho nh·ªØng sentiment words (√°o n√†y ƒë·∫πp--> √°o n√†y ƒë·∫πp positive)\n",
        "            if cp_text in pos_list:\n",
        "                texts.append('positive')\n",
        "            elif cp_text in nag_list:\n",
        "                texts.append('nagative')\n",
        "\n",
        "    text = u' '.join(texts)\n",
        "\n",
        "    #remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i\n",
        "    text = text.replace(u'\"', u' ')\n",
        "    text = text.replace(u'Ô∏è', u'')\n",
        "    text = text.replace('üèª','')\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beGHCeZaxnbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"data_in_dataframe.csv\", sep='\\t')\n",
        "del df['Unnamed: 0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK_cY1tL7AZf",
        "colab_type": "code",
        "outputId": "0cf4d139-1e31-47a9-dcfe-01320e67a4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "for i in range(len(df)):\n",
        "  te = normalize_text(df.loc[i, 'sentence'])\n",
        "  df.loc[i, 'sentence'] = te\n",
        "  print('\\r', i*100/len(df), '%', end='')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0.9999682136045772 %"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qGoVjDi7RbM",
        "colab_type": "code",
        "outputId": "f92fa0b3-c64c-4c07-c38d-18ff15098f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>type</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>√°o bao ƒë·∫πp ·∫° positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tuy·ªát v·ªùi positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2day ao kh√¥ng giong trong</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>m√πi th∆°m b√¥i l√™n da m·ªÅm da nagative</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v·∫£i ƒë·∫πp d√†y d·∫∑n positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31455</th>\n",
              "      <td>kh√¥ng ƒë√°ng ti·ªÅn</td>\n",
              "      <td>NEG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31456</th>\n",
              "      <td>qu·∫ßn r·∫•t ƒë·∫πp positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31457</th>\n",
              "      <td>h√†ng ƒë·∫πp ƒë√∫ng gi√° ti·ªÅn positive positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31458</th>\n",
              "      <td>ch·∫•t v·∫£i kh√° ·ªïn positive</td>\n",
              "      <td>POS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31459</th>\n",
              "      <td>√°o r·∫•t ok nh√© v·∫£i m·ªãn len cao c·ªï n√†y ph·ªëi form...</td>\n",
              "      <td>POS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31460 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence type  point\n",
              "0                                  √°o bao ƒë·∫πp ·∫° positive  POS      5\n",
              "1                                     tuy·ªát v·ªùi positive  POS      5\n",
              "2                              2day ao kh√¥ng giong trong  NEG      1\n",
              "3                    m√πi th∆°m b√¥i l√™n da m·ªÅm da nagative  POS      5\n",
              "4                               v·∫£i ƒë·∫πp d√†y d·∫∑n positive  POS      5\n",
              "...                                                  ...  ...    ...\n",
              "31455                                    kh√¥ng ƒë√°ng ti·ªÅn  NEG      1\n",
              "31456                              qu·∫ßn r·∫•t ƒë·∫πp positive  POS      5\n",
              "31457           h√†ng ƒë·∫πp ƒë√∫ng gi√° ti·ªÅn positive positive  POS      5\n",
              "31458                           ch·∫•t v·∫£i kh√° ·ªïn positive  POS      4\n",
              "31459  √°o r·∫•t ok nh√© v·∫£i m·ªãn len cao c·ªï n√†y ph·ªëi form...  POS      5\n",
              "\n",
              "[31460 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7htJocBG7QX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('preprocessed_df.csv', sep='\\t', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwnvF_GSz1S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp preprocessed_df.csv drive/My\\ 'Drive/Colab Notebooks/NLP_1920_FinalExam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5UZjlxj4txT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}